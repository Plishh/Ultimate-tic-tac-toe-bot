{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9ad99-c7de-4be4-86e2-341946177bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "from utils import State, Action  # Assuming this is available from your project files\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                             stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                             stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                         stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dea55a-7ebd-417d-87ad-6f1f54df5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_features(state):\n",
    "    # Basic features from your original function\n",
    "    board = state.board.flatten()  # 81 elements\n",
    "    board = np.where(board == 2, -1, board)  # 0→0, 1→1, 2→-1\n",
    "    local_status = state.local_board_status.flatten()  # 9 elements\n",
    "    local_status = np.where(local_status == 2, -1, \n",
    "                           np.where(local_status == 3, 0, local_status))  # 0→0, 1→1, 2→-1, 3→0\n",
    "    fill_num = [1 if state.fill_num == 1 else -1]  # 1 element\n",
    "    prev_action = np.array(state.prev_local_action) if state.prev_local_action is not None else np.array([-1, -1])  # 2 elements\n",
    "    \n",
    "    # Additional features\n",
    "    # 1. Count of pieces per player\n",
    "    player1_count = np.sum(board == 1)  # 1 element\n",
    "    player2_count = np.sum(board == -1)  # 1 element\n",
    "    \n",
    "    # 2. Local board completion status (fraction of filled cells per local board)\n",
    "    board_3d = state.board.reshape(3, 3, 9)  # Reshape to (meta_row, meta_col, local_cells)\n",
    "    local_filled = np.count_nonzero(board_3d, axis=2).flatten() / 9.0  # 9 elements\n",
    "    \n",
    "    # 3. Threat detection (simplified: count of 2-in-a-rows possible)\n",
    "    def count_twos(board_2d):\n",
    "        count = 0\n",
    "        for row in board_2d:\n",
    "            if np.sum(row == 1) == 2 and np.sum(row == 0) == 1: count += 1\n",
    "            if np.sum(row == -1) == 2 and np.sum(row == 0) == 1: count += 1\n",
    "        return count\n",
    "    \n",
    "    board_2d = state.board.reshape(9, 9)  # Treat as 9 local boards\n",
    "    threat_count = count_twos(board_2d) + count_twos(board_2d.T)  # Rows and columns, 1 element\n",
    "    \n",
    "    # Concatenate all features\n",
    "    features = np.concatenate([\n",
    "        board,           # 81\n",
    "        local_status,    # 9\n",
    "        fill_num,        # 1\n",
    "        prev_action,     # 2\n",
    "        [player1_count], # 1\n",
    "        [player2_count], # 1\n",
    "        local_filled,    # 9\n",
    "        [threat_count]   # 1\n",
    "    ])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f80ee4-f2c7-4380-a823-55290c807dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from utils import load_data\n",
    "\n",
    "data = load_data()\n",
    "X = np.array([state_to_features(state) for state, _ in data])\n",
    "y = np.array([value for _, value in data]).reshape(-1, 1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y, test_size=0.15, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d127b8-6c72-4401-ab71-fde13593d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetUTTT(nn.Module):\n",
    "    def __init__(self, num_blocks=2, num_features=64):\n",
    "        super(ResNetUTTT, self).__init__()\n",
    "        \n",
    "        # Input processing for flat features (105 elements)\n",
    "        self.initial_fc = nn.Linear(105, num_features * 9)  # Transform to 576 (e.g., 64*9)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features)\n",
    "        \n",
    "        # Reshape to 2D for convolutions (num_features channels, 3x3)\n",
    "        self.layer1 = self._make_layer(num_features, num_features, num_blocks)\n",
    "        self.layer2 = self._make_layer(num_features, num_features*2, num_blocks, stride=2)\n",
    "        \n",
    "        # Final layers\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(num_features*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 105)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Transform flat features to 2D\n",
    "        out = self.initial_fc(x)  # (batch_size, num_features * 9)\n",
    "        out = out.view(batch_size, -1, 3, 3)  # (batch_size, num_features, 3, 3)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        \n",
    "        # Residual layers\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        # Final processing\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = torch.tanh(self.fc2(out))  # Output between -1 and 1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34bec8e-e863-4085-8acf-7ec04a19d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"CPU\")\n",
    "print(device)\n",
    "model = ResNetUTTT().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edd699-ef13-4055-af87-adb5b28fb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "        # Update scheduler based on epoch loss (for ReduceLROnPlateau)\n",
    "        scheduler.step(loss.item())\n",
    "print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d489e24-abbd-4751-9209-096a3841c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "criterion = nn.HuberLoss(delta=0.5)\n",
    "X_temp_tensor = torch.tensor(X_temp, dtype=torch.float32).to(device)\n",
    "y_temp_tensor = torch.tensor(y_temp, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        # Set model to evaluation mode\n",
    "#model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "model.eval()\n",
    "    \n",
    "    # Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    # Get predictions\n",
    "    temp_outputs = model(X_temp_tensor)\n",
    "    # Calculate temporary data loss\n",
    "    temp_loss = criterion(temp_outputs, y_temp_tensor).to(device)\n",
    "        \n",
    "    # Convert predictions to numpy for easier analysis\n",
    "    #torch.tensor.cpu()\n",
    "    y_temp_pred = temp_outputs.detach().cpu().numpy()\n",
    "    \n",
    "# Calculate additional metrics\n",
    "temp_mse = mean_squared_error(y_temp, y_temp_pred)\n",
    "temp_r2 = r2_score(y_temp, y_temp_pred)\n",
    "    \n",
    "# Print evaluation metrics\n",
    "print(f\"Temporary Data Loss: {temp_loss.item()}\")\n",
    "print(f\"Temporary Data MSE: {temp_mse}\")\n",
    "print(f\"Temporary Data R²: {temp_r2}\")\n",
    "    \n",
    "print( temp_loss.item(), temp_mse, temp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeecfdd-2597-4425-9c50-7d4872b0ebf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=float('inf'), precision=10, linewidth=10000)\n",
    "\n",
    "# Then print in OrderedDict format\n",
    "output = \"OrderedDict([\\n\"\n",
    "for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "    # Convert tensor to a full string representation\n",
    "    tensor_str = repr(param)\n",
    "    end_char = \",\" if i < len(model.state_dict()) - 1 else \"\"\n",
    "    output += f\"    ('{name}', {tensor_str}){end_char}\\n\"\n",
    "output += \"])\"\n",
    "\n",
    "# Save the output to a text file\n",
    "with open('model_state_dict.txt', 'w') as file:\n",
    "    file.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f3898-c106-4cef-9dfd-bb7de245d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90429d-681b-465b-a025-4c4369904c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4e3dc-9669-4787-b52a-6b871db66b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
